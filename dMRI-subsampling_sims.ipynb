{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Single-voxel simulations\n",
    "\n",
    "Monte-Carlo simulations were performed for a single-voxel representative of white-matter, to evaluate the impact of each subsampling method (SC vs TRUNC) on the estimation of diffusion parameters derived from DTI (i.e., FA, MD, AD, and RD maps) and DKI (i.e., MK, AK, and RK maps). We simulated the diffusion-weighted signal under different background noise conditions (SNR=10, 20, 30, 40, 50).  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: dipy in /home/afouto/.local/lib/python3.8/site-packages (1.1.1)\n",
      "Requirement already satisfied: h5py>=2.4.0 in /home/afouto/.local/lib/python3.8/site-packages (from dipy) (2.10.0)\n",
      "Requirement already satisfied: scipy>=1.0 in /usr/local/lib/python3.8/dist-packages (from dipy) (1.8.0)\n",
      "Requirement already satisfied: nibabel>=3.0.0 in /usr/local/lib/python3.8/dist-packages (from dipy) (3.2.2)\n",
      "Requirement already satisfied: numpy>=1.7 in /usr/local/lib/python3.8/dist-packages (from h5py>=2.4.0->dipy) (1.22.3)\n",
      "Requirement already satisfied: six in /home/afouto/PROJECTS/virtualenvs/project-dwi_subsampling/lib/python3.8/site-packages (from h5py>=2.4.0->dipy) (1.15.0)\n",
      "Requirement already satisfied: packaging>=14.3 in /usr/local/lib/python3.8/dist-packages (from nibabel>=3.0.0->dipy) (21.3)\n",
      "Requirement already satisfied: setuptools in /home/afouto/PROJECTS/virtualenvs/project-dwi_subsampling/lib/python3.8/site-packages (from nibabel>=3.0.0->dipy) (44.0.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /home/afouto/PROJECTS/virtualenvs/project-dwi_subsampling/lib/python3.8/site-packages (from packaging>=14.3->nibabel>=3.0.0->dipy) (2.4.7)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install dipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import time\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Parallelization\n",
    "import multiprocessing\n",
    "\n",
    "# Export data\n",
    "import csv\n",
    "\n",
    "# module to load nifti images\n",
    "import nibabel as nib\n",
    "import numpy as np\n",
    "\n",
    "# fucntion to construct gradient table and design matrix\n",
    "from dipy.core.gradients import gradient_table\n",
    "from dipy.core.sphere import HemiSphere, disperse_charges\n",
    "\n",
    "#from dipy.data import fetch_stanford_hardi, read_stanford_hardi\n",
    "from dipy.io.gradients import read_bvals_bvecs\n",
    "from dipy.data import (get_fnames, get_sphere)\n",
    "\n",
    "# function to compute quadratic form of tensor from evals and evecs\n",
    "from dipy.reconst.dki import decompose_tensor, Wrotate\n",
    "\n",
    "# fucntion to add noise to simulated data\n",
    "from dipy.sims.voxel import dki_signal, multi_tensor_dki, _check_directions, all_tensor_evecs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dki_fitting(info):\n",
    "    np.random.seed(None)\n",
    "    noisy = dki_signal(\n",
    "        info[1],\n",
    "        info[2], \n",
    "        info[3], \n",
    "        S0=info[4],\n",
    "        snr=info[5],\n",
    "    )\n",
    "    return [info[0], noisy]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------------------------------------------------------\n",
    "# Defining working directories:\n",
    "# ------------------------------------------------------------------------------\n",
    "cwd = Path.cwd()\n",
    "path_sims = cwd\n",
    "path_sc = path_sims / \"03-anisotropic_voxel/sc\"\n",
    "path_trunc = path_sims / \"03-anisotropic_voxel/trunc\"\n",
    "path_to_save = path_sims / \"05-sims_signal-nifti/independent\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------------------------------------------------------\n",
    "# Defining simulation parameters\n",
    "# ------------------------------------------------------------------------------\n",
    "# The experiment is repeated for 100 diffusion tensor directions and 100 noise repeats\n",
    "nReps = 100  # number of noise instances\n",
    "nDTdirs = 100  # number of tensor directions\n",
    "SNR = [10, 20, 30, 40, 50, 1000]  # noise levels\n",
    "subsets = [\"full\", \"subset5\", \"subset10\", \"subset20\", \"subset30\", \"subset40\", \"subset50\"] \n",
    "methods = [\"sc\", \"trunc\"] # two different subsampling methods\n",
    "\n",
    "# number of activated cores for parallel processing:\n",
    "n_cores = 12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "S0 signal for a voxel with only tissue is 230.11526488059488\n"
     ]
    }
   ],
   "source": [
    "# ------------------------------------------------------------------------------\n",
    "# Ground truth parameters:\n",
    "# ------------------------------------------------------------------------------\n",
    "# Reference for GT parameters: shorturl.at/EIQV6 - Section 3.2.1.\n",
    "\n",
    "# ------------------------------------------------------------------------------\n",
    "# 1. Simulating diffusion tensor\n",
    "# ------------------------------------------------------------------------------\n",
    "DT0 = np.zeros((3, 3))\n",
    "\n",
    "DT0[0][0] = 0.1783e-3\n",
    "DT0[0][1] = 0.0011e-3\n",
    "DT0[0][2] = 0.0125e-3\n",
    "DT0[1][0] = 0.0011e-3\n",
    "DT0[1][1] = 0.1459e-3\n",
    "DT0[1][2] = 0.0034e-3\n",
    "DT0[2][0] = 0.0125e-3\n",
    "DT0[2][1] = 0.0034e-3\n",
    "DT0[2][2] = 0.4028e-3\n",
    "\n",
    "dt = np.array([DT0[0][0], DT0[0][1], DT0[1][1], DT0[0][2], DT0[1][2], DT0[2][2]])\n",
    "\n",
    "# ------------------------------------------------------------------------------\n",
    "# 2. Simulating kurtosis tensor\n",
    "# ------------------------------------------------------------------------------\n",
    "kt0 = np.zeros((15))\n",
    "\n",
    "kt0[0] = 0.5698\n",
    "kt0[1] = 0.3208\n",
    "kt0[2] = 2.6049\n",
    "kt0[3] = -0.1142\n",
    "kt0[4] = -1.1531\n",
    "kt0[5] = 0.3944\n",
    "kt0[6] = -0.5409\n",
    "kt0[7] = 0.7220\n",
    "kt0[8] = 0.777\n",
    "kt0[9] = 0.2865\n",
    "kt0[10] = 0.4700\n",
    "kt0[11] = 0.2065\n",
    "kt0[12] = -0.0005\n",
    "kt0[13] = 0.1655\n",
    "kt0[14] = -0.4157\n",
    "\n",
    "# ------------------------------------------------------------------------------\n",
    "# 3. Simulating S0 signal\n",
    "# ------------------------------------------------------------------------------\n",
    "# Parameters that define the unweighted signal at 3T (assuming no T1 relaxation):\n",
    "\n",
    "# T2 relaxation (ms)\n",
    "T2_tissue = 80  # Wansapura et al., 1999\n",
    "\n",
    "# Proton density (percentage units)\n",
    "PD_tissue = 70  # Abbas et al., 2015\n",
    "\n",
    "# TE (ms) \n",
    "TE = 89 # MIG_N2Treat project protocol\n",
    "\n",
    "# Assuming no T1 relaxation, the non-weighted signal for a voxel that has only tisssue or only water:\n",
    "k = 10\n",
    "S0_sims = k * PD_tissue * np.exp(-TE / T2_tissue)\n",
    "\n",
    "print('S0 signal for a voxel with only tissue is ' + str(S0_sims))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------------------------------------------------------\n",
    "# Simulate tensor rotations:\n",
    "# ------------------------------------------------------------------------------\n",
    "theta = np.pi * np.random.rand(nDTdirs)\n",
    "phi = 2 * np.pi * np.random.rand(nDTdirs)\n",
    "hsph_initial = HemiSphere(theta=theta, phi=phi)\n",
    "hsph_updated, potential = disperse_charges(hsph_initial, 5000)\n",
    "DTdirs = hsph_updated.vertices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating single-voxel DWIs...\n",
      "Processing sc---------------------------------\n",
      "Processing snr:10---------------------------------\n",
      "Processing full---------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|███▌      | 35/100 [00:24<00:45,  1.42it/s]Process ForkPoolWorker-432:\n",
      "Process ForkPoolWorker-430:\n",
      "Process ForkPoolWorker-422:\n",
      "Process ForkPoolWorker-425:\n",
      "Process ForkPoolWorker-427:\n",
      "Process ForkPoolWorker-421:\n",
      "Process ForkPoolWorker-424:\n",
      "Process ForkPoolWorker-426:\n",
      "Process ForkPoolWorker-431:\n",
      "Process ForkPoolWorker-429:\n",
      "Process ForkPoolWorker-428:\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Process ForkPoolWorker-423:\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.8/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.8/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.8/multiprocessing/queues.py\", line 355, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.8/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.8/multiprocessing/queues.py\", line 355, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.8/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.8/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.8/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.8/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "\n",
      "  File \"/usr/lib/python3.8/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.8/multiprocessing/queues.py\", line 355, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.8/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.8/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.8/multiprocessing/queues.py\", line 355, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.8/multiprocessing/queues.py\", line 355, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.8/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.8/multiprocessing/queues.py\", line 355, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.8/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.8/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.8/multiprocessing/queues.py\", line 355, in get\n",
      "    with self._rlock:\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/lib/python3.8/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.8/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.8/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/lib/python3.8/multiprocessing/queues.py\", line 355, in get\n",
      "    with self._rlock:\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/lib/python3.8/multiprocessing/queues.py\", line 356, in get\n",
      "    res = self._reader.recv_bytes()\n",
      "  File \"/usr/lib/python3.8/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.8/multiprocessing/connection.py\", line 216, in recv_bytes\n",
      "    buf = self._recv_bytes(maxlength)\n",
      "  File \"/usr/lib/python3.8/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.8/multiprocessing/queues.py\", line 355, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.8/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.8/multiprocessing/connection.py\", line 414, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "  File \"/usr/lib/python3.8/multiprocessing/queues.py\", line 355, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.8/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.8/multiprocessing/connection.py\", line 379, in _recv\n",
      "    chunk = read(handle, remaining)\n",
      "  File \"/usr/lib/python3.8/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.8/multiprocessing/queues.py\", line 355, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.8/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/lib/python3.8/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/home/afouto/PROJECTS/MIGRAINE/4_Conferences/2020_ESMRMB/11-Simulations/v011-simulate_xx_snr_independent_corrected.ipynb Cell 11\u001b[0m in \u001b[0;36m<cell line: 5>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/afouto/PROJECTS/MIGRAINE/4_Conferences/2020_ESMRMB/11-Simulations/v011-simulate_xx_snr_independent_corrected.ipynb#X13sZmlsZQ%3D%3D?line=59'>60</a>\u001b[0m \u001b[39m# Busy-waiting: until work is done, check whether any worker dies (in that case, PIDs would change!)\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/afouto/PROJECTS/MIGRAINE/4_Conferences/2020_ESMRMB/11-Simulations/v011-simulate_xx_snr_independent_corrected.ipynb#X13sZmlsZQ%3D%3D?line=60'>61</a>\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mnot\u001b[39;00m fitresults\u001b[39m.\u001b[39mready():\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/afouto/PROJECTS/MIGRAINE/4_Conferences/2020_ESMRMB/11-Simulations/v011-simulate_xx_snr_independent_corrected.ipynb#X13sZmlsZQ%3D%3D?line=61'>62</a>\u001b[0m     fitpool_pids_new \u001b[39m=\u001b[39m [\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/afouto/PROJECTS/MIGRAINE/4_Conferences/2020_ESMRMB/11-Simulations/v011-simulate_xx_snr_independent_corrected.ipynb#X13sZmlsZQ%3D%3D?line=62'>63</a>\u001b[0m         proc\u001b[39m.\u001b[39mpid \u001b[39mfor\u001b[39;00m proc \u001b[39min\u001b[39;00m fitpool\u001b[39m.\u001b[39m_pool\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/afouto/PROJECTS/MIGRAINE/4_Conferences/2020_ESMRMB/11-Simulations/v011-simulate_xx_snr_independent_corrected.ipynb#X13sZmlsZQ%3D%3D?line=63'>64</a>\u001b[0m     ]  \u001b[39m# Get process IDs again\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/afouto/PROJECTS/MIGRAINE/4_Conferences/2020_ESMRMB/11-Simulations/v011-simulate_xx_snr_independent_corrected.ipynb#X13sZmlsZQ%3D%3D?line=64'>65</a>\u001b[0m     \u001b[39mif\u001b[39;00m (\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/afouto/PROJECTS/MIGRAINE/4_Conferences/2020_ESMRMB/11-Simulations/v011-simulate_xx_snr_independent_corrected.ipynb#X13sZmlsZQ%3D%3D?line=65'>66</a>\u001b[0m         fitpool_pids_new \u001b[39m!=\u001b[39m fitpool_pids_initial\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/afouto/PROJECTS/MIGRAINE/4_Conferences/2020_ESMRMB/11-Simulations/v011-simulate_xx_snr_independent_corrected.ipynb#X13sZmlsZQ%3D%3D?line=66'>67</a>\u001b[0m     ):  \u001b[39m# Check whether the IDs have changed from the initial values\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/afouto/PROJECTS/MIGRAINE/4_Conferences/2020_ESMRMB/11-Simulations/v011-simulate_xx_snr_independent_corrected.ipynb#X13sZmlsZQ%3D%3D?line=67'>68</a>\u001b[0m         \u001b[39mprint\u001b[39m(\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/afouto/PROJECTS/MIGRAINE/4_Conferences/2020_ESMRMB/11-Simulations/v011-simulate_xx_snr_independent_corrected.ipynb#X13sZmlsZQ%3D%3D?line=68'>69</a>\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/afouto/PROJECTS/MIGRAINE/4_Conferences/2020_ESMRMB/11-Simulations/v011-simulate_xx_snr_independent_corrected.ipynb#X13sZmlsZQ%3D%3D?line=69'>70</a>\u001b[0m         )  \u001b[39m# Yes, they changed: at least one worker has died! Exit with error\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# ------------------------------------------------------------------------------\n",
    "print(\"Generating single-voxel DWIs...\")\n",
    "# ------------------------------------------------------------------------------\n",
    "\n",
    "for m_i, method in enumerate(methods):\n",
    "    print(\"Processing \" + method + \"---------------------------------\")\n",
    "\n",
    "    if method == \"sc\":\n",
    "        path_out=path_sc\n",
    "    else:\n",
    "        path_out=path_trunc\n",
    "\n",
    "    for snr_i, snr in enumerate(SNR):\n",
    "        print(\"Processing snr:\" + str(snr) + \"---------------------------------\")\n",
    "        \n",
    "        for s_i, subset in enumerate(subsets):\n",
    "            print(\"Processing \" + subset + \"---------------------------------\")\n",
    "\n",
    "            bv1 = subset + \"_\" + method + \"_b0b1000b2000.bvec\"\n",
    "            bv2 = subset + \"_\" + method + \"_b0b1000b2000.bval\"\n",
    "\n",
    "            fbvecs = os.path.join(path_out, bv1)\n",
    "            fbvals = os.path.join(path_out, bv2)\n",
    "\n",
    "            bvals, bvecs = read_bvals_bvecs(str(fbvals), str(fbvecs))\n",
    "            gtab_sims = gradient_table(bvals, bvecs, b0_threshold=0)\n",
    "            \n",
    "            DWIs = np.zeros((nDTdirs * nReps, bvals.size))\n",
    "\n",
    "            for d_i in tqdm(np.arange(nDTdirs)):\n",
    "\n",
    "                time.sleep(0.3)\n",
    "                # for current simulated tensor direction\n",
    "                angles = DTdirs[d_i]\n",
    "                sticks = _check_directions(angles)\n",
    "\n",
    "                R = all_tensor_evecs(sticks)\n",
    "                DT = np.dot(np.dot(R, DT0), R.T)\n",
    "        \n",
    "                eigvals, eigvects = decompose_tensor(DT)\n",
    "\n",
    "                dt_rot = np.array([DT[0][0], DT[0][1], DT[1][1], DT[0][2], DT[1][2], DT[2][2]])\n",
    "\n",
    "                kt_rot = Wrotate(kt0, R.T)\n",
    "\n",
    "                input_list = []\n",
    "                for n_i in np.arange(d_i * nReps, (d_i + 1) * nReps, dtype=int):\n",
    "                    # Fitting DKI model to estimate the tensor parameters:\n",
    "                    slice_info = [n_i, gtab_sims, dt_rot, kt_rot, S0_sims, snr]\n",
    "                    input_list.append(slice_info)\n",
    "\n",
    "                if n_cores is None:\n",
    "                    n_cores = multiprocessing.cpu_count()\n",
    "\n",
    "                fitpool = multiprocessing.Pool(\n",
    "                    processes=n_cores)  # Create parallel processes\n",
    "                fitpool_pids_initial = [proc.pid for proc in fitpool._pool]  # Get initial process identifications (PIDs)\n",
    "                fitresults = fitpool.map_async(dki_fitting, input_list)  # Give jobs to the parallel processes\n",
    "\n",
    "                # Busy-waiting: until work is done, check whether any worker dies (in that case, PIDs would change!)\n",
    "                while not fitresults.ready():\n",
    "                    fitpool_pids_new = [\n",
    "                        proc.pid for proc in fitpool._pool\n",
    "                    ]  # Get process IDs again\n",
    "                    if (\n",
    "                        fitpool_pids_new != fitpool_pids_initial\n",
    "                    ):  # Check whether the IDs have changed from the initial values\n",
    "                        print(\n",
    "                            \"\"\n",
    "                        )  # Yes, they changed: at least one worker has died! Exit with error\n",
    "                        print(\n",
    "                            \"ERROR: some processes died during parallel fitting. Exiting with 1.\"\n",
    "                        )\n",
    "                        print(\"\")\n",
    "                        sys.exit(1)\n",
    "\n",
    "                # Work done: get results\n",
    "                fitlist = fitresults.get()\n",
    "\n",
    "                \n",
    "                # Collect fitting output and re-assemble MRI slices\n",
    "                for fit_i, fit_rep in enumerate(fitlist):\n",
    "                    DWIs[fit_rep[0], :] = fit_rep[1]\n",
    "                        \n",
    "            converted_array = np.asfarray(DWIs, dtype=np.float32)\n",
    "\n",
    "            nifti_array = converted_array.reshape((2, 6, 12, bvals.size))\n",
    "            nifti_file = nib.Nifti2Image(nifti_array, affine=np.eye(4))\n",
    "            \n",
    "            out_dir = os.path.join(path_to_save, 'snr{}'.format(snr), subset)\n",
    "            if not os.path.exists(out_dir):\n",
    "                os.makedirs(out_dir)\n",
    "                \n",
    "            nib.save(nifti_file, os.path.join(out_dir, 'dwi_sims_snr{}_{}_method-{}.nii'.format(snr, subset, method)))"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit ('project-dwi_subsampling': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "50a95c54e9956108271d2931e040fd7ce64b2f56e50f13cdae9ee435e56442f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
